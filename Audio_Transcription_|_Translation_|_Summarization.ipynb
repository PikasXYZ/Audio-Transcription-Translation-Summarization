{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "JYW3CmH0b6df"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PikasXYZ/Audio-Transcription-Translation-Summarization/blob/main/Audio_Transcription_%7C_Translation_%7C_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installation & imports"
      ],
      "metadata": {
        "id": "JYW3CmH0b6df"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yVzkns0ROVmm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebebd2f5-3dd1-49aa-dd01-d2c0f38c68d9",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-cloud-translate in /usr/local/lib/python3.10/dist-packages (3.11.3)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-translate) (2.11.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-translate) (2.3.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-translate) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-translate) (3.20.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate) (1.63.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate) (2.27.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate) (2.31.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate) (1.64.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate) (4.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate) (2024.2.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate) (0.6.0)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#@title Installation\n",
        "!pip install pydub -q\n",
        "!pip install yt-dlp -q\n",
        "!pip install openai -q -U\n",
        "!pip install pytube -q\n",
        "!pip install python-docx -q\n",
        "!pip install SpeechRecognition -q\n",
        "!pip install tiktoken -q -U\n",
        "!pip install google-cloud-translate\n",
        "!pip install git+https://github.com/openai/whisper.git -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title imports\n",
        "# Standard libraries\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import shutil\n",
        "import requests\n",
        "\n",
        "# Third-party libraries\n",
        "from openai import OpenAI\n",
        "import yt_dlp\n",
        "import whisper\n",
        "import requests\n",
        "import tiktoken\n",
        "from docx import Document\n",
        "from pytube import YouTube\n",
        "from bs4 import BeautifulSoup\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "import speech_recognition as sr\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Google libraries\n",
        "from google.cloud import translate\n",
        "import google.colab\n",
        "from google.colab import userdata\n",
        "from google.colab import drive, files\n",
        "\n",
        "# IPython display\n",
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "pFBncVyMTeWG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transcription Functions"
      ],
      "metadata": {
        "id": "_kP1Rv048ZW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Transcribe Audio to Text by Open Source Whisper\n",
        "def opensrc_whisper_transcript2text(audio, print_out, model):\n",
        "  # ref: https://github.com/openai/whisper/blob/main\n",
        "  while \"This loop is to avoid sound chunk being too long\":\n",
        "    try:\n",
        "      chunks = split_on_silence(\n",
        "                    audio,\n",
        "                    min_silence_len = silence, #experiment with this value for your target audio file\n",
        "                    silence_thresh = sound.dBFS-14, #adjust this per requirement\n",
        "                    keep_silence = silence #keep the silence for 0.5 second, adjustable as well\n",
        "                    )\n",
        "\n",
        "      if print_out: print(f\"【Transcription】 (silence={silence}ms)\")\n",
        "\n",
        "      transcriptor = whisper.load_model(model)\n",
        "\n",
        "      output = ''\n",
        "      for i, audio_chunk in enumerate(chunks, start=1):\n",
        "        audio_chunk.export('chunk.wav', format=\"wav\")\n",
        "        try:\n",
        "          result = transcriptor.transcribe('chunk.wav')[\"text\"]\n",
        "          transcript = break_lines(transcript)\n",
        "\n",
        "        except sr.UnknownValueError as e:\n",
        "          print(type(e).__name__,':', str(e))\n",
        "\n",
        "        else:\n",
        "          if print_out: print(transcript)\n",
        "          output += transcript+'\\n'\n",
        "\n",
        "    except:\n",
        "      if silence>=100: silence -= 50\n",
        "      else: raise Exception(\"Cannot deal with this audio, please try another one\")\n",
        "      #print(f\"Sound chunks are too long! Trying to decrease SILENCE to {silence}ms.\")\n",
        "      clear_output(wait=True)\n",
        "\n",
        "    else:\n",
        "      break\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "cellView": "form",
        "id": "BoBykFLl8X5P"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Transcribe Audio to Text by OpenAI Whisper (Faster than the above merely)\n",
        "def OpenAI_whisper_transcript2text(audio, print_out):\n",
        "  #ref: https://platform.openai.com/docs/guides/speech-to-text/quickstart\n",
        "  global openai_client\n",
        "  silence=600\n",
        "  while \"This loop is to avoid sound chunk being too long\":\n",
        "    try:\n",
        "      chunks = split_on_silence(\n",
        "                    audio,\n",
        "                    min_silence_len = silence, #experiment with this value for your target audio file\n",
        "                    silence_thresh = sound.dBFS-14, #adjust this per requirement\n",
        "                    keep_silence = silence #keep the silence for 0.5 second, adjustable as well\n",
        "                    )\n",
        "\n",
        "      if print_out: print(f\"【Transcription】 (silence={silence}ms)\")\n",
        "\n",
        "      output = ''\n",
        "      for i, audio_chunk in enumerate(chunks, start=1):\n",
        "        audio_chunk.export('chunk.wav', format=\"wav\")\n",
        "        audio_file = open('chunk.wav', \"rb\")\n",
        "        try:\n",
        "          transcript = openai_client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file).text\n",
        "          transcript = break_lines(transcript)\n",
        "\n",
        "        except sr.UnknownValueError as e:\n",
        "          print(type(e).__name__,':', str(e))\n",
        "        else:\n",
        "          if print_out: print(transcript)\n",
        "          output += transcript+'\\n'\n",
        "\n",
        "    except:\n",
        "      if silence>=100: silence -= 50\n",
        "      else: raise Exception(\"Cannot deal with this audio, please try another one\")\n",
        "      #print(f\"Sound chunks are too long! Trying to decrease SILENCE to {silence}ms. \")\n",
        "      clear_output(wait=True)\n",
        "\n",
        "    else:\n",
        "      break\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "cellView": "form",
        "id": "v4gTZiFsCYC1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Translation Functions"
      ],
      "metadata": {
        "id": "lDmw9QzXsA9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title OpenAI ChatGPT Translate\n",
        "def OpenAI_ChatGPT_translate(texts, translaion_language, model, print_out):\n",
        "  global openai_client\n",
        "\n",
        "  if type(texts) == str: texts = [texts]\n",
        "\n",
        "  output = \"\"\n",
        "  for text in texts:\n",
        "    messages = [{\"role\":\"system\", \"content\": f\"You are a helpful translator. Please help me to translate following text and output in {translaion_language}.\"}]\n",
        "    messages.append({\"role\": \"user\", \"content\": text})\n",
        "    response = openai_client.chat.completions.create(model=model, messages=messages)\n",
        "    translate = response.choices[0].message.content\n",
        "    translate = break_lines(translate)\n",
        "    if print_out: print(translate)\n",
        "    output += translate\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ft_GfOGbXQ32"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Google Translate\n",
        "def Google_translate(texts: list ,target_language: str, print_out=True) -> str:\n",
        "  texts = [texts] if type(texts) == str else texts\n",
        "\n",
        "  global GOOGLE_TRANSLATE_API_KEY, google_translation_support_languages\n",
        "\n",
        "  output = \"\"\n",
        "  for text in texts:\n",
        "    # ref: https://ithelp.ithome.com.tw/m/articles/10218704\n",
        "\n",
        "    #detect\n",
        "    google_detection_api_url = f\"https://translation.googleapis.com/language/translate/v2/detect/?q={text}&key={GOOGLE_TRANSLATE_API_KEY}\"\n",
        "    response = requests.get(google_detection_api_url)\n",
        "    source_language = response.json().get('data').get('detections')[0][0].get('language')\n",
        "\n",
        "    #check target_language\n",
        "    if target_language not in google_translation_support_languages:\n",
        "      print(f\"\\\"{target_language}\\\" isn't supported by Google Translate, please try the following:\")\n",
        "      print('\\n'.join([key for key, item in google_translation_support_languages.items()]))\n",
        "      raise Exception(\"translaion_language Error!\")\n",
        "\n",
        "    #translate\n",
        "    google_translation_api_url = f\"https://translation.googleapis.com/language/translate/v2/?q={text}&source={source_language}&target={google_translation_support_languages[target_language]}&key={GOOGLE_TRANSLATE_API_KEY}\"\n",
        "    response = requests.get(google_translation_api_url)\n",
        "    try:\n",
        "      translate = break_lines(response.json().get('data').get('translations')[0].get('translatedText'))\n",
        "      if print_out: print(translate)\n",
        "      output += translate\n",
        "    except Exception as e:\n",
        "      print(f\"Request failed with status code {response.status_code}\")\n",
        "      print(type(e).__name__)\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "B5HJBFjZBhp6",
        "cellView": "form"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Summarization Functions"
      ],
      "metadata": {
        "id": "PVPQmRtqsMCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Summarize w/ OpenAI ChatGPT\n",
        "def summarize(texts, language, model, print_out):\n",
        "  global openai_client\n",
        "\n",
        "  if type(texts) == str: texts = [texts]\n",
        "\n",
        "  output = ''\n",
        "  for text in texts:\n",
        "    messages = [{\"role\":\"system\", \"content\": f\"Please summarize following audio transcription content briefly and output in {language}.\"}]\n",
        "    messages.append({\"role\": \"user\", \"content\": text})\n",
        "    response = openai_client.chat.completions.create(model=model, messages=messages)\n",
        "    reply = response.choices[0].message.content\n",
        "    reply = break_lines(reply)\n",
        "    if print_out: print(reply)\n",
        "    output += reply\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "cellView": "form",
        "id": "c7QLLe5ufG-Y"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Other Functions"
      ],
      "metadata": {
        "id": "g-HSIrwNsX6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Break Lines\n",
        "def break_lines(text: str) -> str:\n",
        "    pattern = r'([。？！.?!])'\n",
        "    lines = [line.strip() for line in re.split(pattern, text) if line]\n",
        "\n",
        "    result = []\n",
        "    for i in range(0, len(lines), 2):\n",
        "      lines[i] += lines[i+1] if i+1 < len(lines) else ''\n",
        "      result.append(lines[i])\n",
        "\n",
        "    return '\\n'.join(result)\n",
        "print(break_lines(\"Hello! How are you?\"))"
      ],
      "metadata": {
        "id": "tN1eC35AsC5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a5def4-5a55-473b-fdc6-f025c67b2db2",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello!\n",
            "How are you?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Split the Text to Prevent it Containing Too More Token\n",
        "# encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "def split_by_token(text, spliter = '\\n', max_token = 2999):\n",
        "  #Initialize\n",
        "  text_chunks = text.split(spliter)\n",
        "  texts = []\n",
        "\n",
        "  #Split\n",
        "  output = ''\n",
        "  for chunk in text_chunks:\n",
        "    if len(encoding.encode(output + chunk)) >= max_token:\n",
        "      texts.append(output)\n",
        "      output = chunk + spliter\n",
        "    else:\n",
        "      output += chunk + spliter\n",
        "  else:\n",
        "    texts.append(output)\n",
        "\n",
        "  return texts"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GJL8ghjk8XsY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Output as docx\n",
        "def save_as_docx(text, filename):\n",
        "  if os.path.exists(filename): os.remove(filename)\n",
        "  document = Document()\n",
        "  document.add_paragraph(text)\n",
        "  document.save(filename)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "M-Pg8wqkwp7m"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Output as txt\n",
        "def save_as_txt(text, filename):\n",
        "  if os.path.exists(filename): os.remove(filename)\n",
        "  document = open(filename, \"w\")\n",
        "  document.write(text)\n",
        "  document.close"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2FMqxnkwjEir"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get Userdata Safely\n",
        "def get_userdata_safely(key):\n",
        "  #What's userdata.get? https://drlee.io/how-to-use-secrets-in-google-colab-for-api-key-protection-a-guide-for-openai-huggingface-and-c1ec9e1277e0\n",
        "  try:\n",
        "    data = userdata.get(key)\n",
        "    print(f\"Userdata found! ({key = })\")\n",
        "  except:\n",
        "    data = \"\"\n",
        "    print(f\"Userdata not found! ({key = })\")\n",
        "  return data"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FTpEIOWxXndi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "gJO79HQlD7nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title settings\n",
        "GOOGLE_TRANSLATE_API_KEY = get_userdata_safely('GOOGLE_TRANSLATE_API_KEY')\n",
        "GEMINI_API_KEY = get_userdata_safely('GEMINI_API_KEY')\n",
        "OPENAI_API_KEY = get_userdata_safely('OPENAI_API_KEY')\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "dORIoYVfD6N2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "830efef0-070f-4088-8fec-cbe7b8aa4cd1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Userdata found! (key = 'GOOGLE_TRANSLATE_API_KEY')\n",
            "Userdata found! (key = 'GEMINI_API_KEY')\n",
            "Userdata found! (key = 'OPENAI_API_KEY')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title get Google translation support languages\n",
        "if GOOGLE_TRANSLATE_API_KEY:\n",
        "  google_translation_support_languages_api_url = f\"https://translation.googleapis.com/language/translate/v2/languages/?target=en&key={GOOGLE_TRANSLATE_API_KEY}\"\n",
        "  response = requests.get(google_translation_support_languages_api_url)\n",
        "  google_translation_support_languages = {x['name']:x['language'] for x in response.json().get('data').get('languages')}\n",
        "  print(\"【Google translation support languages】\")\n",
        "  for k,v in google_translation_support_languages.items():\n",
        "    print(f\"{k} ({v})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt_XB8HPGjj6",
        "outputId": "45fc957c-5003-4bce-bad7-3d145e214d3a",
        "cellView": "form"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "【Google translation support languages】\n",
            "Afrikaans (af)\n",
            "Albanian (sq)\n",
            "Amharic (am)\n",
            "Arabic (ar)\n",
            "Armenian (hy)\n",
            "Assamese (as)\n",
            "Aymara (ay)\n",
            "Azerbaijani (az)\n",
            "Bambara (bm)\n",
            "Basque (eu)\n",
            "Belarusian (be)\n",
            "Bengali (bn)\n",
            "Bhojpuri (bho)\n",
            "Bosnian (bs)\n",
            "Bulgarian (bg)\n",
            "Catalan (ca)\n",
            "Cebuano (ceb)\n",
            "Chichewa (ny)\n",
            "Chinese (Simplified) (zh-CN)\n",
            "Chinese (Traditional) (zh-TW)\n",
            "Corsican (co)\n",
            "Croatian (hr)\n",
            "Czech (cs)\n",
            "Danish (da)\n",
            "Divehi (dv)\n",
            "Dogri (doi)\n",
            "Dutch (nl)\n",
            "English (en)\n",
            "Esperanto (eo)\n",
            "Estonian (et)\n",
            "Ewe (ee)\n",
            "Filipino (tl)\n",
            "Finnish (fi)\n",
            "French (fr)\n",
            "Frisian (fy)\n",
            "Galician (gl)\n",
            "Ganda (lg)\n",
            "Georgian (ka)\n",
            "German (de)\n",
            "Greek (el)\n",
            "Guarani (gn)\n",
            "Gujarati (gu)\n",
            "Haitian Creole (ht)\n",
            "Hausa (ha)\n",
            "Hawaiian (haw)\n",
            "Hebrew (he)\n",
            "Hindi (hi)\n",
            "Hmong (hmn)\n",
            "Hungarian (hu)\n",
            "Icelandic (is)\n",
            "Igbo (ig)\n",
            "Iloko (ilo)\n",
            "Indonesian (id)\n",
            "Irish Gaelic (ga)\n",
            "Italian (it)\n",
            "Japanese (ja)\n",
            "Javanese (jv)\n",
            "Kannada (kn)\n",
            "Kazakh (kk)\n",
            "Khmer (km)\n",
            "Kinyarwanda (rw)\n",
            "Konkani (gom)\n",
            "Korean (ko)\n",
            "Krio (kri)\n",
            "Kurdish (Kurmanji) (ku)\n",
            "Kurdish (Sorani) (ckb)\n",
            "Kyrgyz (ky)\n",
            "Lao (lo)\n",
            "Latin (la)\n",
            "Latvian (lv)\n",
            "Lingala (ln)\n",
            "Lithuanian (lt)\n",
            "Luxembourgish (lb)\n",
            "Macedonian (mk)\n",
            "Maithili (mai)\n",
            "Malagasy (mg)\n",
            "Malay (ms)\n",
            "Malayalam (ml)\n",
            "Maltese (mt)\n",
            "Maori (mi)\n",
            "Marathi (mr)\n",
            "Meiteilon (Manipuri) (mni-Mtei)\n",
            "Mizo (lus)\n",
            "Mongolian (mn)\n",
            "Myanmar (Burmese) (my)\n",
            "Nepali (ne)\n",
            "Northern Sotho (nso)\n",
            "Norwegian (no)\n",
            "Odia (Oriya) (or)\n",
            "Oromo (om)\n",
            "Pashto (ps)\n",
            "Persian (fa)\n",
            "Polish (pl)\n",
            "Portuguese (pt)\n",
            "Punjabi (pa)\n",
            "Quechua (qu)\n",
            "Romanian (ro)\n",
            "Russian (ru)\n",
            "Samoan (sm)\n",
            "Sanskrit (sa)\n",
            "Scots Gaelic (gd)\n",
            "Serbian (sr)\n",
            "Sesotho (st)\n",
            "Shona (sn)\n",
            "Sindhi (sd)\n",
            "Sinhala (si)\n",
            "Slovak (sk)\n",
            "Slovenian (sl)\n",
            "Somali (so)\n",
            "Spanish (es)\n",
            "Sundanese (su)\n",
            "Swahili (sw)\n",
            "Swedish (sv)\n",
            "Tajik (tg)\n",
            "Tamil (ta)\n",
            "Tatar (tt)\n",
            "Telugu (te)\n",
            "Thai (th)\n",
            "Tigrinya (ti)\n",
            "Tsonga (ts)\n",
            "Turkish (tr)\n",
            "Turkmen (tk)\n",
            "Twi (ak)\n",
            "Ukrainian (uk)\n",
            "Urdu (ur)\n",
            "Uyghur (ug)\n",
            "Uzbek (uz)\n",
            "Vietnamese (vi)\n",
            "Welsh (cy)\n",
            "Xhosa (xh)\n",
            "Yiddish (yi)\n",
            "Yoruba (yo)\n",
            "Zulu (zu)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Settings of OpenAI (Ignorable if not going to use relative tools)\n",
        "#@markdown ####What model to use?<br/>\n",
        "GPT_model = \"gpt-3.5-turbo\" #@param [\"gpt-4o\",\"gpt-4-turbo\",\"gpt-3.5-turbo\"]"
      ],
      "metadata": {
        "id": "fMP7XwyDAE7F",
        "cellView": "form"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Main\n",
        "###⚠️After changing any parameter in a cell, please run that cell again.⚠️\n",
        "####⚠️After changing any parameter in a cell, please run that cell again.⚠️\n",
        "#####⚠️After changing any parameter in a cell, please run that cell again.⚠️"
      ],
      "metadata": {
        "id": "kBrhx7JvcAEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Video(s) or Audio(s)\n",
        "#@markdown ### Choose the source of video or audio:\n",
        "#@markdown ##### ㅤ\n",
        "source = \"share link of Google Drive\" #@param [\"Youtube URL\",\"file path of Google Drive\",\"folder path of Google Drive\",\"share link of Google Drive\", \"upload from my computer\"]\n",
        "#@markdown ##### ㅤ\n",
        "#@markdown ### Set path/URL according to the source you choose:\n",
        "#@markdown ##### ㅤ\n",
        "youtube_url = \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\" #@param {type:\"string\"}\n",
        "file_path_of_Google_Drive = \"/content/drive/MyDrive/Rick Astley - Never Gonna Give You Up (Official Music Video).mp3\" #@param {type:\"string\"}\n",
        "folder_path_of_Google_Drive = \"/content/drive/MyDrive/\" #@param {type:\"string\"}\n",
        "share_link_of_Google_Drive = \"https://drive.google.com/file/d/1RxvmTPfHzaVBmSH99Ds6x7R4xecFmABz/view?usp=drive_link\" #@param {type:\"string\"}\n",
        "#@markdown ##### ㅤ\n",
        "#@markdown ### Save mp3:\n",
        "#@markdown ##### ㅤ\n",
        "YouTube_mp3_to_my_computer = False #@param {type:\"boolean\"}\n",
        "YouTube_mp3_to_Google_Drive = False #@param {type:\"boolean\"}\n",
        "output_folder_of_Google_Drive = \"/content/drive/MyDrive\" #@param {type:\"string\"}\n",
        "\n",
        "if YouTube_mp3_to_Google_Drive:\n",
        "  drive.mount('/content/drive')\n",
        "  if not os.path.isdir(output_folder_of_Google_Drive):\n",
        "    os.mkdir(output_folder_of_Google_Drive)\n",
        "\n",
        "match source:\n",
        "  case _ if source.startswith(\"Youtube URL\"):\n",
        "    #set YouTube download options\n",
        "    ydl_opts = {\n",
        "          'format': 'bestaudio/best',\n",
        "          'outtmpl': \"%(title)s.%(ext)s\",\n",
        "          'postprocessors': [{\n",
        "                    'key': 'FFmpegExtractAudio',\n",
        "                    'preferredcodec': 'mp3', #download type\n",
        "                    'preferredquality': '192',\n",
        "                    }],\n",
        "          'ignoreerrors': True #Ignore private videos\n",
        "          }\n",
        "\n",
        "    sounds = []\n",
        "    filenames = []\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "      info_dict = ydl.extract_info(youtube_url, download = True) #Extract info. from YT URL\n",
        "      audios = info_dict['entries'] if 'entries' in info_dict else [info_dict] #'entries' appears in info_dict when multiple videos are downloaded.\n",
        "      for audio in audios:\n",
        "        try:\n",
        "          filename = os.path.splitext(ydl.prepare_filename(audio))[0]\n",
        "          filenames.append(filename)\n",
        "          sounds.append(AudioSegment.from_mp3(filename+'.mp3'))\n",
        "          if YouTube_mp3_to_Google_Drive:\n",
        "            shutil.copy2(filename+'.mp3', output_folder_of_Google_Drive)\n",
        "          if YouTube_mp3_to_my_computer:\n",
        "            google.colab.files.download(filename+'.mp3')\n",
        "        except Exception as e:\n",
        "          print(type(e).__name__,\" : \",str(e))\n",
        "\n",
        "\n",
        "    def on_dl_button_clicked(button):\n",
        "      for audio in audios:\n",
        "        try: filename = os.path.splitext(ydl.prepare_filename(audio))[0]\n",
        "        except: print(\"Found an invalid video.\")\n",
        "        else: google.colab.files.download(filename+'.mp3')\n",
        "\n",
        "    dl_buttton = widgets.Button(description=\"Download Again\")\n",
        "    dl_buttton.on_click(on_dl_button_clicked)\n",
        "    if YouTube_mp3_to_my_computer:\n",
        "      display(dl_buttton) #Unknown error usually occurs while lots of videos are downloading.\n",
        "\n",
        "  case \"file path of Google Drive\":\n",
        "    drive.mount('/content/drive')\n",
        "    filenames = [os.path.splitext(os.path.basename(file_path_of_Google_Drive))[0]]\n",
        "    sounds = [AudioSegment.from_file(file_path_of_Google_Drive)]\n",
        "\n",
        "  case \"folder path of Google Drive\":\n",
        "    drive.mount('/content/drive')\n",
        "    filenames = []\n",
        "    sounds = []\n",
        "    for root, dirs, files in os.walk(folder_path_of_Google_Drive):\n",
        "      for name in files:\n",
        "        if name.endswith(('.mp4', '.mov', '.avi', '.mkv', '.mp3', '.wav', '.flac')):\n",
        "          filenames.append(name.split('.')[0])\n",
        "          sounds.append(AudioSegment.from_file(os.path.join(root, name)))\n",
        "\n",
        "  case \"share link of Google Drive\":\n",
        "    assert share_link_of_Google_Drive.startswith(\"https://drive.google.com/file/d/\"), \"Invalid Google Drive link format\"\n",
        "    file_id = share_link_of_Google_Drive.split(\"https://drive.google.com/file/d/\")[-1].split(\"/\")[0]\n",
        "\n",
        "    try:\n",
        "      response = requests.get(share_link_of_Google_Drive)\n",
        "      soup = BeautifulSoup(response.text, 'html.parser')\n",
        "      filenames = [soup.find('title').text.strip().split(\" - Google Drive\")[0]]\n",
        "    except:\n",
        "      filenames = [\"download\"]\n",
        "\n",
        "    filename = filenames[0]\n",
        "    !gdown --id $file_id --output \"$filename\"\n",
        "    sounds = [AudioSegment.from_file(filenames[0])]\n",
        "\n",
        "  case \"upload from my computer\":\n",
        "    filenames = []\n",
        "    sounds = []\n",
        "    upload = google.colab.files.upload()\n",
        "    for k in upload.keys():\n",
        "      if k.endswith(('.mp4', '.mov', '.avi', '.mkv', '.mp3', '.wav', '.flac')):\n",
        "        filenames.append(k.split('.')[0])\n",
        "        sounds.append(AudioSegment.from_file(k))\n",
        "\n",
        "  case _:\n",
        "    raise Exception(\"Source Error!\")\n",
        "\n",
        "#print out content unless there're multiple files to process\n",
        "print_out_content = len(sounds)==1"
      ],
      "metadata": {
        "id": "yAV8xkUhOkle",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7688f59-9ce8-4fa9-d97f-46c9a687524b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RxvmTPfHzaVBmSH99Ds6x7R4xecFmABz\n",
            "To: /content/Never Gonna Give You Up.mp3\n",
            "100% 3.39M/3.39M [00:00<00:00, 76.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Transcription\n",
        "#@markdown ####Settings:ㅤ\n",
        "transcription_tool = \"OpenAI-whisper\" #@param [\"OpenAI-whisper\", \"whisper-tiny\", \"whisper-base\", \"whisper-small\", \"whisper-medium\", \"whisper-large\", \"whisper-tiny.en\", \"whisper-base.en\", \"whisper-small.en\", \"whisper-medium.en\"]\n",
        "output_type = \"txt\" #@param [\"txt\",\"docx\"]\n",
        "output_to_my_computer = False #@param {type:\"boolean\"}\n",
        "output_to_Google_Drive = False #@param {type:\"boolean\"}\n",
        "output_folder_of_Google_Drive = \"/content/drive/MyDrive\" #@param {type:\"string\"}\n",
        "if output_to_Google_Drive:\n",
        "  drive.mount('/content/drive')\n",
        "  if not os.path.isdir(output_folder_of_Google_Drive):\n",
        "    os.mkdir(output_folder_of_Google_Drive)\n",
        "\n",
        "transcription_output_chunks_list = []\n",
        "for sound, filename in zip(sounds, filenames):\n",
        "\n",
        "  #transcription process\n",
        "  match transcription_tool:\n",
        "    case \"OpenAI-whisper\":\n",
        "        transcription_output = OpenAI_whisper_transcript2text(sound,\n",
        "                                    print_out_content)\n",
        "    case _ if \"whisper-\" in transcription_tool:\n",
        "        transcription_output = opensrc_whisper_transcript2text(sound,\n",
        "                                     print_out_content,\n",
        "                                     transcription_tool.split('-')[-1])\n",
        "  if not print_out_content:\n",
        "    print(filename, \" is transcripted.\")\n",
        "  transcription_output_chunks = split_by_token(transcription_output)\n",
        "  transcription_output_chunks_list.append(transcription_output_chunks)\n",
        "\n",
        "  #transcription output\n",
        "  output_name = f\"{filename}_transcripted_by_{transcription_tool}.{output_type}\"\n",
        "  match output_type:\n",
        "    case \"txt\":\n",
        "      save_as_txt(transcription_output, output_name)\n",
        "    case \"docx\":\n",
        "      save_as_docx(transcription_output, output_name)\n",
        "\n",
        "  #save files\n",
        "  if output_to_Google_Drive:\n",
        "    shutil.copy2(output_name, output_folder_of_Google_Drive)\n",
        "  if output_to_my_computer:\n",
        "    google.colab.files.download(output_name)"
      ],
      "metadata": {
        "id": "XfeeQGUQQOwx",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2efbe295-f5a9-4bf2-b8f3-1de977434e9a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "【Transcription】 (silence=150ms)\n",
            "BOOM\n",
            "We're no strangers to love You know the rules, and so do I I feel commitments while I'm thinking of You wouldn't get this from any other guy I just wanna tell you how I'm feeling Gotta make you understand Never gonna give you up Never gonna let you down Never gonna run around and desert you Never gonna make you cry Never gonna say goodbye Never gonna tell a lie and hurt you We've known each other for so long Your heart's been aching but you're too shy to say it Inside we both know what's been going on We know the game and we're gonna play it And if you ask me how I'm feeling Don't tell me you're too blind to see Never gonna give you up Never gonna let you down Never gonna run around and desert you Never gonna make you cry Never gonna say goodbye Never gonna tell a lie and hurt you Never gonna give you up Never gonna let you down Never gonna run around and desert you Never gonna make you cry Never gonna say goodbye Never gonna tell a lie and hurt you Give you up Give you up Never gonna give you up Never gonna give you up We've known each other\n",
            "For so long Your heart's been aching but You're too shy to say it Inside we both know what's been Going on We know the game and we're Gonna play it I Just wanna tell you how I'm feeling Gotta make you understand Never gonna give you up Never gonna let you down Never gonna run around And desert you Never gonna make you cry Never gonna say goodbye Never gonna tell a lie And hurt you Never gonna give you up Never gonna let you down Never gonna run around And desert you Never gonna make you cry Never gonna say goodbye Never gonna tell a lie And hurt you Never gonna give you up Never gonna let you down Never gonna run around And desert you\n",
            "♪ Deserve you, and I'm gonna hate you ♪\n",
            "고맙습니다.\n",
            "All right.\n",
            "♪ Oh, say.\n",
            "..\n",
            "♪\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Translation (⚠️Transcription must be done before)\n",
        "#@markdown ####Settings:\n",
        "translation_tool = \"OpenAI-ChatGPT\" #@param [\"OpenAI-ChatGPT\",\"Google-Translate\"]\n",
        "language = \"Chinese (Traditional)\" #@param {type: \"string\"}\n",
        "output_type = \"txt\" #@param [\"txt\",\"docx\"]\n",
        "output_to_my_computer = False #@param {type:\"boolean\"}\n",
        "output_to_Google_Drive = False #@param {type:\"boolean\"}\n",
        "output_folder_of_Google_Drive = \"/content/drive/MyDrive\" #@param {type:\"string\"}\n",
        "if output_to_Google_Drive:\n",
        "  drive.mount('/content/drive')\n",
        "  if not os.path.isdir(output_folder_of_Google_Drive):\n",
        "    os.mkdir(output_folder_of_Google_Drive)\n",
        "\n",
        "for transcription_output_chunks, filename in zip(transcription_output_chunks_list, filenames):\n",
        "\n",
        "  #translation process\n",
        "  output = \"Error! \"*10+'\\n'\n",
        "  match translation_tool:\n",
        "    case \"Google-Translate\":\n",
        "        output = Google_translate(transcription_output_chunks,\n",
        "                      language,\n",
        "                      print_out_content)\n",
        "    case \"OpenAI-ChatGPT\":\n",
        "        output = OpenAI_ChatGPT_translate(transcription_output_chunks,\n",
        "                          language,\n",
        "                          GPT_model,\n",
        "                          print_out_content)\n",
        "\n",
        "  if not print_out_content:\n",
        "    print(filename, \" is translated.\")\n",
        "\n",
        "  #translation output\n",
        "  output_name = f\"{filename}_translated_by_{translation_tool}.{output_type}\"\n",
        "  match output_type:\n",
        "    case \"txt\":\n",
        "        save_as_txt(output, output_name)\n",
        "    case \"docx\":\n",
        "        save_as_docx(output, output_name)\n",
        "\n",
        "  #save files\n",
        "  if output_to_Google_Drive:\n",
        "    shutil.copy2(output_name, output_folder_of_Google_Drive)\n",
        "  if output_to_my_computer:\n",
        "    google.colab.files.download(output_name)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "edlmQ0Lq6MNu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73752893-2533-46ce-a6ad-d4b8fe012d44"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOOM\n",
            "我們並不陌生 我們都知道規矩 我感到投入當我想起 你不會從其他人那裡得到這些 我只想告訴你我的感受 必須讓你明白 永遠不會放棄你 永遠不會讓你失望 永遠不會四處亂跑並拋棄你 永遠不會讓你哭泣 永遠不會說再見 永遠不會說謊傷害你 我們彼此相識已久 你的心一直在痛苦但你太害羞說出口 我們內心明白發生了什麼 我們知道這場遊戲並將一起玩 要是你問我感受 如何 別告訴我你太盲目看不見 永遠不會放棄你 永遠不會讓你失望 永遠不會四處亂跑並拋棄你 永遠不會讓你哭泣 永遠不會說再見 永遠不會說謊傷害你 永遠不會放棄你 永遠不會讓你失望 永遠不會四處亂跑並拋棄你 永遠不會讓你哭泣 永遠不會說再見 永遠不會說謊傷害你 永遠不會放棄你 永遠不會讓你失望 永遠不會四處亂跑並拋棄你 ♪ 洗掉你，我將憎惡你 ♪ 謝謝你。\n",
            "好的。\n",
            "♪ 喔，說。\n",
            "♪\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Summarization (⚠️Transcription must be done before)\n",
        "#@markdown ####Settings:\n",
        "output_type = \"txt\" #@param [\"txt\",\"docx\"]\n",
        "language = \"Chinese (Traditional)\" #@param {type: \"string\"}\n",
        "output_to_my_computer = False #@param {type:\"boolean\"}\n",
        "output_to_Google_Drive = False #@param {type:\"boolean\"}\n",
        "output_folder_of_Google_Drive = \"/content/drive/MyDrive\" #@param {type:\"string\"}\n",
        "if output_to_Google_Drive:\n",
        "  drive.mount('/content/drive')\n",
        "  if not os.path.isdir(output_folder_of_Google_Drive):\n",
        "    os.mkdir(output_folder_of_Google_Drive)\n",
        "\n",
        "for transcription_output_chunks, filename in zip(transcription_output_chunks_list, filenames):\n",
        "\n",
        "  #summarization output\n",
        "  output = summarize(transcription_output_chunks,\n",
        "            language,\n",
        "            GPT_model,\n",
        "            print_out_content)\n",
        "\n",
        "  if not print_out_content: print(filename, \" is summarized.\")\n",
        "\n",
        "  #summarization output\n",
        "  output_name = f\"{filename}_summarized.{output_type}\"\n",
        "  match output_type:\n",
        "    case \"txt\":\n",
        "        save_as_txt(output, output_name)\n",
        "    case \"docx\":\n",
        "        save_as_docx(output, output_name)\n",
        "\n",
        "  #save files\n",
        "  if output_to_Google_Drive:\n",
        "    shutil.copy2(output_name, output_folder_of_Google_Drive)\n",
        "  if output_to_my_computer:\n",
        "    google.colab.files.download(output_name)"
      ],
      "metadata": {
        "id": "u2d8ZWdW6n-Q",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e6b406b-cfa4-4c81-bb49-a0bd2a7ed71e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "這段內容是一首歌曲的歌詞，描述了一個人對另一個人的承諾和愛意。\n"
          ]
        }
      ]
    }
  ]
}